{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cbea3f7",
   "metadata": {},
   "source": [
    "# RL Pipeline Notebook\n",
    "This notebook runs the analysis pipeline using the translated Python modules.\n",
    "\n",
    "## New Output Structure\n",
    "All processed data and results are now saved to the `python_output` directory, organized as follows:\n",
    "- `trial_data/`: Processed trial data at various stages\n",
    "- `estimation_data/`: Processed estimation data\n",
    "- `analysis_results/`: Statistical analysis results and plots\n",
    "- `reports/`: Summary reports and metadata in JSON format\n",
    "\n",
    "Each module will save its outputs to these directories, making it easier to inspect the results at each stage of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb1690fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCAL_DATA_DIR: /Users/edeneldar/Documents/RL/RL_Maggie/Data\n",
      "STRESS_DATA_DIR: /Users/edeneldar/Documents/RL/RL_Maggie/data_healthy_Noa\n"
     ]
    }
   ],
   "source": [
    "from importlib import import_module\n",
    "setup = import_module('00_setup')\n",
    "print('LOCAL_DATA_DIR:', setup.LOCAL_DATA_DIR)\n",
    "print('STRESS_DATA_DIR:', setup.STRESS_DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a361f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: copy raw files from shared drive if available\n",
    "# copy_mod = import_module('RL_Maggie.python.01_copy_raw_files')\n",
    "# copy_mod.copy_files_from_rl(setup.RAW_SHARED_DIR, setup.LOCAL_DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68752c34",
   "metadata": {},
   "source": [
    "## Trial-Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a95ddc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty file: /Users/edeneldar/Documents/RL/RL_Maggie/Data/sub_901_Reversal_2024-02-19_16h00.26.975.csv\n",
      "Fibro participants: 31 healthy, 161 fibro\n",
      "Stress participants: 56 total\n",
      "Non-learners: 37 fibro/healthy, 46 stress\n",
      "Fibro participants: 31 healthy, 161 fibro\n",
      "Stress participants: 56 total\n",
      "Non-learners: 37 fibro/healthy, 46 stress\n"
     ]
    }
   ],
   "source": [
    "# Import modules for trial data processing\n",
    "fibro_mod = import_module('02_trial_etl_fibro')\n",
    "stress_mod = import_module('03_trial_etl_stress')\n",
    "\n",
    "# Get trial data for both groups\n",
    "res_fibro = fibro_mod.get_trial_data_healthy_fibro(setup.LOCAL_DATA_DIR)\n",
    "res_stress = stress_mod.get_trial_data_healthy_stress()\n",
    "\n",
    "# Print some basic information about the results\n",
    "print(f\"Fibro participants: {len(res_fibro['healthy_participants'])} healthy, {len(res_fibro['fibro_participants'])} fibro\")\n",
    "print(f\"Stress participants: {len(res_stress['participants_with_7_blocks'])} total\")\n",
    "print(f\"Non-learners: {len(res_fibro['non_learners'])} fibro/healthy, {len(res_stress['non_learners'])} stress\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82965bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial rows: 11373\n"
     ]
    }
   ],
   "source": [
    "merge_mod = import_module('04_trial_merge_clean')\n",
    "full_trial_data = merge_mod.full_trial_data\n",
    "full_trial_data_learners = merge_mod.full_trial_data_learners\n",
    "all_non_learners = merge_mod.all_non_learners\n",
    "print('Trial rows:', len(full_trial_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42c174f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Load and run trial analysis\n",
    "try:\n",
    "    analysis_mod = import_module('05_trial_analysis')\n",
    "    print(\"\\nAnalysis completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nWarning: Analysis encountered an issue: {e}\")\n",
    "    print(\"You may need to check the balance of your data or modify the analysis approach.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e27b15",
   "metadata": {},
   "source": [
    "## Estimation-Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12b2cbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation rows: 6587\n"
     ]
    }
   ],
   "source": [
    "# Import estimation ETL module with error handling\n",
    "try:\n",
    "    est_etl = import_module('06_estimation_etl')\n",
    "    # Access data if available\n",
    "    if hasattr(est_etl, 'full_estimation_data') and hasattr(est_etl, 'full_estimation_data_clean'):\n",
    "        full_estimation_data = est_etl.full_estimation_data\n",
    "        full_estimation_data_clean = est_etl.full_estimation_data_clean\n",
    "        print('Estimation rows:', len(full_estimation_data))\n",
    "    else:\n",
    "        print('Warning: Estimation data not available')\n",
    "except Exception as e:\n",
    "    print(f'Error loading estimation data: {e}')\n",
    "    print('Creating empty estimation dataframes to continue pipeline')\n",
    "    import pandas as pd\n",
    "    full_estimation_data = pd.DataFrame()\n",
    "    full_estimation_data_clean = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41763709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation analysis completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Load estimation analysis with error handling\n",
    "try:\n",
    "    estimation_analysis_mod = import_module('07_estimation_analysis')\n",
    "    print('Estimation analysis completed successfully')\n",
    "except Exception as e:\n",
    "    print(f'Error in estimation analysis: {e}')\n",
    "    print('Try running the notebook again to verify if the fixes for estimation_etl worked')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aee7cf5",
   "metadata": {},
   "source": [
    "## Questionnaire Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "514bd262",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '08_questionnaire_analysis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m08_questionnaire_analysis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuestionnaire file missing:\u001b[39m\u001b[38;5;124m'\u001b[39m, e)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/new_base/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '08_questionnaire_analysis'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import_module('08_questionnaire_analysis')\n",
    "except FileNotFoundError as e:\n",
    "    print('Questionnaire file missing:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0da705",
   "metadata": {},
   "source": [
    "## Note on Fixed Issues\n",
    "\n",
    "The code was fixed to address the following issues:\n",
    "\n",
    "1. Fixed indentation errors in `03_trial_etl_stress.py`\n",
    "2. Added proper import for `STRESS_DATA_DIR` from the setup module\n",
    "3. Fixed the code that identifies participants with 7 blocks in both stress and fibro modules\n",
    "4. Modified the ANOVA analysis in `05_trial_analysis.py` to handle unbalanced data:\n",
    "   - Added diagnostics to check data balance\n",
    "   - Implemented a fallback to standard ANOVA if repeated measures ANOVA fails\n",
    "   - Added better error handling and reporting\n",
    "5. Enhanced error handling in `06_estimation_etl.py` to handle missing columns:\n",
    "   - Added robust error handling for missing 'high_prob_image_file' and other required columns\n",
    "   - Added detailed error messages to identify problematic files\n",
    "   - Modified the notebook to continue pipeline execution even if estimation data processing fails\n",
    "6. Fixed the boolean column access in `07_estimation_analysis.py`:\n",
    "   - Changed direct boolean column access to string-based column access\n",
    "   - Added proper error handling for missing data\n",
    "   - Added checks to ensure sufficient data for ANOVA analysis\n",
    "\n",
    "These changes improve the robustness of the pipeline by preventing errors related to participant indexing, indentation, unbalanced data in statistical analyses, missing columns in input files, and unsafe boolean column access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b22d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the output directory structure\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "setup = import_module('00_setup')\n",
    "OUTPUT_DIR = setup.OUTPUT_DIR\n",
    "\n",
    "def print_directory_contents(directory, indent=''):\n",
    "    \"\"\"Print the contents of a directory in a tree-like format\"\"\"\n",
    "    if not directory.exists():\n",
    "        print(f\"{indent}Directory does not exist: {directory}\")\n",
    "        return\n",
    "        \n",
    "    print(f\"{indent}📁 {directory.name}/\")\n",
    "    indent += '  '\n",
    "    \n",
    "    # Get all files and directories\n",
    "    items = list(directory.iterdir())\n",
    "    \n",
    "    # Sort directories first, then files\n",
    "    dirs = sorted([item for item in items if item.is_dir()])\n",
    "    files = sorted([item for item in items if item.is_file()])\n",
    "    \n",
    "    # Print directories\n",
    "    for d in dirs:\n",
    "        print_directory_contents(d, indent)\n",
    "    \n",
    "    # Print files\n",
    "    for f in files:\n",
    "        file_size = f.stat().st_size / 1024  # Size in KB\n",
    "        print(f\"{indent}📄 {f.name} ({file_size:.1f} KB)\")\n",
    "\n",
    "# Print the output directory structure\n",
    "print(\"Output Directory Structure:\")\n",
    "print_directory_contents(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343c8952",
   "metadata": {},
   "source": [
    "## Output Files Overview\n",
    "\n",
    "### Trial Data Files\n",
    "- `fibro_healthy_trial_data.csv`: Trial data for fibromyalgia and healthy control participants\n",
    "- `stress_trial_data.csv`: Trial data for healthy stress participants\n",
    "- `full_trial_data.csv`: Combined trial data from all groups\n",
    "- `full_trial_data_learners.csv`: Trial data excluding non-learners\n",
    "\n",
    "### Estimation Data Files\n",
    "- `full_estimation_data.csv`: Complete estimation data from all participants\n",
    "- `full_estimation_data_clean.csv`: Cleaned estimation data (excludes non-learners and low-variability participants)\n",
    "- `participant_estimation_variability.csv`: Variability measures for each participant's estimation responses\n",
    "\n",
    "### Analysis Results\n",
    "- `anova_input_data.csv`: Data prepared for ANOVA analysis\n",
    "- `standard_anova_results.csv`: Results from standard ANOVA analysis\n",
    "- `rm_anova_results.csv`: Results from repeated measures ANOVA (when available)\n",
    "- `choice_summary_by_group.csv`: Summary statistics of choice behavior by group, block, and pair type\n",
    "- `estimation_summary_by_group.csv`: Summary statistics of estimation behavior by group, block, and pair type\n",
    "\n",
    "### Reports (JSON files)\n",
    "- `data_structure.json`: Information about the structure of the data (participants, blocks, etc.)\n",
    "- `anova_results.json`: Results from ANOVA analyses in a structured format\n",
    "- `participant_summary.json`: Summary statistics about participants in each group\n",
    "- `all_non_learners.json`: List of non-learner participants\n",
    "\n",
    "### Plots\n",
    "- `choice_plot_*.png`: Plots of choice behavior for each group\n",
    "- `estimation_plot_*.png`: Plots of estimation behavior for each group and pair type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4c6775",
   "metadata": {},
   "source": [
    "## Generating an Output Report\n",
    "\n",
    "After running the pipeline, you can generate a detailed report of all output files using the `output_report.py` script:\n",
    "\n",
    "```python\n",
    "import importlib\n",
    "report_mod = importlib.import_module('output_report')\n",
    "```\n",
    "\n",
    "Or from the command line:\n",
    "\n",
    "```bash\n",
    "cd /Users/edeneldar/Documents/RL\n",
    "python RL_Maggie/python/output_report.py\n",
    "```\n",
    "\n",
    "This will:\n",
    "1. Scan all files in the `python_output` directory\n",
    "2. Generate a detailed JSON report of each file (size, content, modification time)\n",
    "3. Save the report to `python_output/reports/output_report.json`\n",
    "4. Print a summary of all files to the console\n",
    "\n",
    "This report is useful for:\n",
    "- Verifying that all expected output files were created\n",
    "- Checking file sizes and row counts\n",
    "- Finding the most recently modified files\n",
    "- Documenting the analysis outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
